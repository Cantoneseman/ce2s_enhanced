"""
äº‘è¾¹ç«¯å­˜å‚¨ç³»ç»Ÿ - ä¸»å®éªŒæ¨¡å—
æ•´åˆ Clientã€EdgeProcessorã€SmartSchedulerã€CloudNode è¿›è¡Œå¯¹æ¯”å®éªŒ
"""

import os
import time
import random
import threading
from pathlib import Path
from typing import List, Dict, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed

from tqdm import tqdm

# å¯¼å…¥ç³»ç»Ÿæ¨¡å—
from client import Client
from edge_core import EdgeProcessor, ChunkStatus, RedundancyType
from scheduler import SmartScheduler
from cloud_mock import CLOUD_NODES, CloudNode


@dataclass
class ExperimentResult:
    """å®éªŒç»“æœ"""
    scenario: str                    # åœºæ™¯åç§°
    total_time: float               # æ€»è€—æ—¶ï¼ˆç§’ï¼‰
    avg_latency: float              # å¹³å‡å»¶è¿Ÿï¼ˆç§’ï¼‰
    total_chunks: int               # æ€»å—æ•°
    uploaded_chunks: int            # å®é™…ä¸Šä¼ å—æ•°
    total_bytes: int                # æ€»æ•°æ®é‡
    uploaded_bytes: int             # å®é™…ä¸Šä¼ æ•°æ®é‡
    cloud_distribution: Dict[str, int]  # å„äº‘èŠ‚ç‚¹ä¸Šä¼ åˆ†å¸ƒ


class CE2SExperiment:
    """
    äº‘è¾¹ç«¯å­˜å‚¨ç³»ç»Ÿå®éªŒç±»
    
    å®éªŒæµç¨‹ï¼š
    Client åŠ å¯† -> Edge FastCDC åˆ†å— -> Edge æ··åˆå†—ä½™ -> Scheduler è°ƒåº¦ -> Cloud ä¸Šä¼ 
    """
    
    def __init__(self, output_dir: str = "./experiment_output"):
        """åˆå§‹åŒ–å®éªŒç¯å¢ƒ"""
        self.client = Client(client_id="exp_client")
        self.edge = EdgeProcessor(edge_id="exp_edge")
        self.scheduler = SmartScheduler(cloud_nodes=CLOUD_NODES)
        
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å®éªŒç»Ÿè®¡
        self.results: List[ExperimentResult] = []
    
    def generate_test_file(self, size_mb: float = 5.0) -> bytes:
        """
        ç”Ÿæˆéšæœºæµ‹è¯•æ–‡ä»¶
        
        Args:
            size_mb: æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
            
        Returns:
            éšæœºäºŒè¿›åˆ¶æ•°æ®
        """
        size_bytes = int(size_mb * 1024 * 1024)
        print(f"ğŸ“ ç”Ÿæˆ {size_mb}MB éšæœºæµ‹è¯•æ•°æ®...")
        return os.urandom(size_bytes)
    
    def generate_modified_file(self, original: bytes, modify_ratio: float = 0.1) -> bytes:
        """
        ç”Ÿæˆä¿®æ”¹åçš„æ–‡ä»¶ï¼ˆç”¨äºæµ‹è¯•å»é‡ï¼‰
        
        Args:
            original: åŸå§‹æ•°æ®
            modify_ratio: ä¿®æ”¹æ¯”ä¾‹
            
        Returns:
            ä¿®æ”¹åçš„æ•°æ®
        """
        data = bytearray(original)
        modify_size = int(len(data) * modify_ratio)
        
        # éšæœºé€‰æ‹©ä½ç½®è¿›è¡Œä¿®æ”¹
        start_pos = random.randint(0, len(data) - modify_size)
        new_content = os.urandom(modify_size)
        data[start_pos:start_pos + modify_size] = new_content
        
        print(f"ğŸ“ ä¿®æ”¹äº† {modify_ratio*100:.0f}% çš„å†…å®¹ ({modify_size} bytes)")
        return bytes(data)
    
    def run_pipeline(self, data: bytes, scenario: str, 
                     use_smart_scheduler: bool = True) -> ExperimentResult:
        """
        è¿è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†å’Œä¸Šä¼ æµç¨‹
        
        Args:
            data: åŸå§‹æ•°æ®
            scenario: åœºæ™¯åç§°
            use_smart_scheduler: æ˜¯å¦ä½¿ç”¨æ™ºèƒ½è°ƒåº¦
            
        Returns:
            å®éªŒç»“æœ
        """
        print(f"\n{'='*60}")
        print(f"ğŸš€ è¿è¡Œåœºæ™¯: {scenario}")
        print(f"{'='*60}")
        
        start_time = time.time()
        cloud_distribution = {node.cloud_id: 0 for node in CLOUD_NODES}
        total_latency = 0.0
        uploaded_chunks = 0
        uploaded_bytes = 0
        
        # Step 1: Client åŠ å¯†
        print("\n[1/4] ğŸ” å®¢æˆ·ç«¯åŠ å¯† (AES-GCM)...")
        encrypted_data, key, nonce = self.client.encrypt_data(data)
        print(f"      åŸå§‹: {len(data)} bytes -> å¯†æ–‡: {len(encrypted_data)} bytes")
        
        # Step 2: Edge FastCDC åˆ†å—
        print("\n[2/4] ğŸ”ª è¾¹ç¼˜èŠ‚ç‚¹ FastCDC åˆ†å—...")
        chunks = self.edge.process(encrypted_data)
        print(f"      æ€»å—æ•°: {len(chunks)}")
        
        new_chunks = [c for c in chunks if c.status == ChunkStatus.NEW]
        ref_chunks = [c for c in chunks if c.status == ChunkStatus.REF]
        print(f"      æ–°å—: {len(new_chunks)}, å¼•ç”¨å—: {len(ref_chunks)}")
        
        # Step 3 & 4: å†—ä½™ç¼–ç  + äº‘ç«¯ä¸Šä¼ 
        print("\n[3/4] ğŸ”„ æ··åˆå†—ä½™ç¼–ç ...")
        print("[4/4] â˜ï¸  ä¸Šä¼ åˆ°äº‘å­˜å‚¨...")
        
        # å‡†å¤‡ä¸Šä¼ ä»»åŠ¡åˆ—è¡¨
        upload_tasks = []
        
        # æ™ºèƒ½è°ƒåº¦ï¼šé¢„å…ˆè·å– Top 3 èŠ‚ç‚¹åˆ—è¡¨ï¼Œè½®æµåˆ†é…ä»»åŠ¡ä»¥åˆ©ç”¨å¹¶å‘
        if use_smart_scheduler:
            best_nodes = self.scheduler.select_best_nodes(k=3)
            best_node_list = [node for node, score in best_nodes]
            print(f"      æ™ºèƒ½è°ƒåº¦é€‰æ‹©èŠ‚ç‚¹: {[n.cloud_id for n in best_node_list]}")
        
        task_idx = 0
        for chunk in new_chunks:
            # é€‰æ‹©äº‘èŠ‚ç‚¹
            if use_smart_scheduler:
                # æ™ºèƒ½è°ƒåº¦ï¼šè½®æµä½¿ç”¨ Top 3 èŠ‚ç‚¹ï¼Œå……åˆ†åˆ©ç”¨å¹¶å‘
                target_node = best_node_list[task_idx % len(best_node_list)]
            else:
                # éšæœºé€‰æ‹©
                target_node = random.choice(CLOUD_NODES)
            
            # ä¸ºæ¯ä¸ªåˆ†ç‰‡åˆ›å»ºä¸Šä¼ ä»»åŠ¡
            for shard_idx, shard in enumerate(chunk.shards):
                filename = f"{chunk.fingerprint[:16]}_{shard_idx}.shard"
                
                if use_smart_scheduler:
                    # åˆ†ç‰‡ä¹Ÿè½®æµåˆ†é…åˆ°ä¸åŒèŠ‚ç‚¹
                    shard_target = best_node_list[task_idx % len(best_node_list)]
                    upload_tasks.append((shard_target, shard, filename))
                else:
                    upload_tasks.append((target_node, shard, filename))
                task_idx += 1
        
        # çº¿ç¨‹å®‰å…¨çš„ç»Ÿè®¡æ›´æ–°é”
        stats_lock = threading.Lock()
        
        def upload_shard(task):
            """å•ä¸ªåˆ†ç‰‡ä¸Šä¼ ä»»åŠ¡"""
            target_node, shard, filename = task
            result = target_node.upload(shard, filename)
            return {
                'cloud_id': target_node.cloud_id,
                'latency': result['latency'],
                'size': len(shard)
            }
        
        # ä½¿ç”¨ ThreadPoolExecutor å¹¶å‘ä¸Šä¼ 
        with ThreadPoolExecutor(max_workers=20) as executor:
            # æ‰¹é‡æäº¤æ‰€æœ‰ä»»åŠ¡
            futures = {executor.submit(upload_shard, task): task for task in upload_tasks}
            
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
            with tqdm(total=len(futures), desc="      ä¸Šä¼ è¿›åº¦", unit="shard") as pbar:
                for future in as_completed(futures):
                    result = future.result()
                    
                    # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»Ÿè®¡
                    with stats_lock:
                        total_latency += result['latency']
                        uploaded_chunks += 1
                        uploaded_bytes += result['size']
                        cloud_distribution[result['cloud_id']] += 1
                        
                        # æ›´æ–°è°ƒåº¦å™¨ç»Ÿè®¡ï¼ˆç”¨äº EWMAï¼‰
                        if use_smart_scheduler:
                            self.scheduler.update_stats(result['cloud_id'], result['latency'])
                    
                    pbar.update(1)
        
        end_time = time.time()
        total_time = end_time - start_time
        avg_latency = total_latency / uploaded_chunks if uploaded_chunks > 0 else 0
        
        # åˆ›å»ºç»“æœ
        result = ExperimentResult(
            scenario=scenario,
            total_time=total_time,
            avg_latency=avg_latency,
            total_chunks=len(chunks),
            uploaded_chunks=uploaded_chunks,
            total_bytes=len(encrypted_data),
            uploaded_bytes=uploaded_bytes,
            cloud_distribution=cloud_distribution
        )
        
        self.results.append(result)
        return result
    
    def print_result(self, result: ExperimentResult) -> None:
        """æ‰“å°å•ä¸ªå®éªŒç»“æœ"""
        print(f"\nğŸ“Š {result.scenario} ç»“æœ:")
        print(f"   æ€»è€—æ—¶: {result.total_time:.3f}s")
        print(f"   å¹³å‡å»¶è¿Ÿ: {result.avg_latency*1000:.2f}ms")
        print(f"   ä¸Šä¼ å—æ•°: {result.uploaded_chunks}")
        print(f"   ä¸Šä¼ æ•°æ®é‡: {result.uploaded_bytes/1024:.2f}KB")
        print(f"   äº‘èŠ‚ç‚¹åˆ†å¸ƒ: {result.cloud_distribution}")
    
    def compare_results(self, baseline: ExperimentResult, 
                        proposed: ExperimentResult) -> None:
        """å¯¹æ¯”ä¸¤ç§åœºæ™¯çš„ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“ˆ å¯¹æ¯”åˆ†æ")
        print("="*60)
        
        # è€—æ—¶å¯¹æ¯”
        time_diff = baseline.total_time - proposed.total_time
        time_improve = (time_diff / baseline.total_time) * 100 if baseline.total_time > 0 else 0
        print(f"\nâ±ï¸  æ€»è€—æ—¶:")
        print(f"   Baseline:  {baseline.total_time:.3f}s")
        print(f"   Proposed:  {proposed.total_time:.3f}s")
        print(f"   æå‡: {time_improve:+.2f}%")
        
        # å»¶è¿Ÿå¯¹æ¯”
        latency_diff = baseline.avg_latency - proposed.avg_latency
        latency_improve = (latency_diff / baseline.avg_latency) * 100 if baseline.avg_latency > 0 else 0
        print(f"\nğŸŒ å¹³å‡å»¶è¿Ÿ:")
        print(f"   Baseline:  {baseline.avg_latency*1000:.2f}ms")
        print(f"   Proposed:  {proposed.avg_latency*1000:.2f}ms")
        print(f"   æå‡: {latency_improve:+.2f}%")
        
        # äº‘èŠ‚ç‚¹åˆ†å¸ƒ
        print(f"\nâ˜ï¸  äº‘èŠ‚ç‚¹åˆ†å¸ƒ:")
        print(f"   Baseline:  {baseline.cloud_distribution}")
        print(f"   Proposed:  {proposed.cloud_distribution}")
    
    def run_dedup_experiment(self, original_data: bytes) -> None:
        """
        è¿è¡Œå»é‡å®éªŒï¼šä¸Šä¼ ä¿®æ”¹äº† 10% å†…å®¹çš„æ–‡ä»¶
        
        æ³¨æ„ï¼šå»é‡æµ‹è¯•åœ¨åŸå§‹æ•°æ®å±‚é¢è¿›è¡Œï¼ˆä¸åŠ å¯†ï¼‰ï¼Œ
        å› ä¸ºåŠ å¯†ä½¿ç”¨éšæœº key/nonce ä¼šå¯¼è‡´ç›¸åŒæ•°æ®äº§ç”Ÿä¸åŒå¯†æ–‡ã€‚
        """
        print("\n" + "="*60)
        print("ğŸ”„ å»é‡æ•ˆæœå®éªŒ")
        print("="*60)
        
        # ä½¿ç”¨æ–°çš„è¾¹ç¼˜å¤„ç†å™¨è¿›è¡Œå»é‡æµ‹è¯•
        dedup_edge = EdgeProcessor(edge_id="exp_edge_dedup")
        
        # Step 1: å…ˆå¤„ç†åŸå§‹æ•°æ®ï¼Œå»ºç«‹æŒ‡çº¹è¡¨
        print("\nğŸ“¥ ç¬¬ä¸€æ¬¡ä¸Šä¼ ï¼šå¤„ç†åŸå§‹æ•°æ®...")
        chunks_first = dedup_edge.process(original_data)
        first_stats = dedup_edge.get_stats()
        print(f"   æ€»å—æ•°: {first_stats['total_chunks']}, æ–°å—: {first_stats['new_chunks']}")
        
        # Step 2: å¤åˆ¶åŸå§‹æ•°æ®å¹¶åªä¿®æ”¹ä¸­é—´ 10%
        print("\nğŸ“ ç”Ÿæˆä¿®æ”¹åçš„æ•°æ®ï¼ˆåªä¿®æ”¹ä¸­é—´ 10%ï¼‰...")
        modified_data = bytearray(original_data)
        
        # è®¡ç®—ä¸­é—´ 10% çš„ä½ç½®
        data_len = len(modified_data)
        modify_size = int(data_len * 0.1)  # 10% çš„æ•°æ®é‡
        start_pos = (data_len - modify_size) // 2  # ä»ä¸­é—´å¼€å§‹
        
        # ç”¨éšæœºæ•°æ®è¦†ç›–ä¸­é—´éƒ¨åˆ†
        new_content = os.urandom(modify_size)
        modified_data[start_pos:start_pos + modify_size] = new_content
        modified_data = bytes(modified_data)
        
        print(f"   åŸå§‹æ•°æ®å¤§å°: {data_len} bytes")
        print(f"   ä¿®æ”¹èŒƒå›´: å­—èŠ‚ {start_pos} ~ {start_pos + modify_size}")
        print(f"   ä¿®æ”¹å¤§å°: {modify_size} bytes ({modify_size/data_len*100:.1f}%)")
        
        # Step 3: é‡ç½®ç»Ÿè®¡ï¼ˆä½†ä¿ç•™æŒ‡çº¹è¡¨ç”¨äºå»é‡æ£€æµ‹ï¼‰
        dedup_edge.reset_stats()
        
        # Step 4: å¤„ç†ä¿®æ”¹åçš„æ•°æ®
        print("\nğŸ“¤ ç¬¬äºŒæ¬¡ä¸Šä¼ ï¼šå¤„ç†ä¿®æ”¹åçš„æ•°æ®...")
        chunks_second = dedup_edge.process(modified_data)
        
        stats = dedup_edge.get_stats()
        
        print(f"\nğŸ“Š å»é‡ç»Ÿè®¡:")
        print(f"   æ€»å—æ•°: {stats['total_chunks']}")
        print(f"   æ–°å—: {stats['new_chunks']}")
        print(f"   å¼•ç”¨å—ï¼ˆå»é‡ï¼‰: {stats['ref_chunks']}")
        print(f"   å»é‡èŠ‚çœ: {stats['bytes_saved']} bytes")
        
        # è®¡ç®—å»é‡ç‡
        if stats['total_chunks'] > 0:
            dedup_ratio = stats['ref_chunks'] / stats['total_chunks'] * 100
        else:
            dedup_ratio = 0
        print(f"   å»é‡ç‡: {dedup_ratio:.2f}%")
        
        # è®¡ç®—å®é™…ä¸Šä¼ æ•°æ®é‡å‡å°‘
        new_upload_bytes = sum(c.size for c in chunks_second if c.status == ChunkStatus.NEW)
        total_bytes = sum(c.size for c in chunks_second)
        reduction = (1 - new_upload_bytes / total_bytes) * 100 if total_bytes > 0 else 0
        
        print(f"\n   åŸå§‹éœ€ä¸Šä¼ : {total_bytes} bytes")
        print(f"   å®é™…éœ€ä¸Šä¼ : {new_upload_bytes} bytes")
        print(f"   æ•°æ®é‡å‡å°‘: {reduction:.2f}%")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå¯¹æ¯”å®éªŒ"""
    print("â•”" + "â•"*58 + "â•—")
    print("â•‘" + " CE2S: Cloud-Edge-End Storage System ".center(58) + "â•‘")
    print("â•‘" + " äº‘è¾¹ç«¯å­˜å‚¨ç³»ç»Ÿ - å¯¹æ¯”å®éªŒ ".center(52) + "â•‘")
    print("â•š" + "â•"*58 + "â•")
    
    # åˆå§‹åŒ–å®éªŒ
    experiment = CE2SExperiment()
    
    # ç”Ÿæˆ 5MB æµ‹è¯•æ•°æ®
    test_data = experiment.generate_test_file(size_mb=5.0)
    
    # ============================================
    # åœºæ™¯ A: Baseline - éšæœºé€‰æ‹©äº‘èŠ‚ç‚¹
    # ============================================
    # é‡ç½®è¾¹ç¼˜å¤„ç†å™¨
    experiment.edge = EdgeProcessor(edge_id="exp_edge_baseline")
    baseline_result = experiment.run_pipeline(
        data=test_data,
        scenario="åœºæ™¯A: Baseline (éšæœºé€‰æ‹©)",
        use_smart_scheduler=False
    )
    experiment.print_result(baseline_result)
    
    # ============================================
    # åœºæ™¯ B: Proposed - æ™ºèƒ½è°ƒåº¦
    # ============================================
    # é‡ç½®è¾¹ç¼˜å¤„ç†å™¨å’Œè°ƒåº¦å™¨
    experiment.edge = EdgeProcessor(edge_id="exp_edge_proposed")
    experiment.scheduler = SmartScheduler(cloud_nodes=CLOUD_NODES)
    
    # é¢„çƒ­è°ƒåº¦å™¨ï¼šæ¨¡æ‹Ÿä¸€äº›å†å²æ•°æ®
    print("\nğŸ”¥ é¢„çƒ­è°ƒåº¦å™¨ (æ¨¡æ‹Ÿå†å²å»¶è¿Ÿæ•°æ®)...")
    for _ in range(10):
        for node in CLOUD_NODES:
            fake_latency = random.gauss(node.latency_mean, node.latency_std)
            experiment.scheduler.update_stats(node.cloud_id, max(0, fake_latency))
    
    proposed_result = experiment.run_pipeline(
        data=test_data,
        scenario="åœºæ™¯B: Proposed (æ™ºèƒ½è°ƒåº¦)",
        use_smart_scheduler=True
    )
    experiment.print_result(proposed_result)
    
    # ============================================
    # å¯¹æ¯”åˆ†æ
    # ============================================
    experiment.compare_results(baseline_result, proposed_result)
    
    # ============================================
    # å»é‡å®éªŒ
    # ============================================
    # ä½¿ç”¨ Proposed åœºæ™¯çš„è¾¹ç¼˜å¤„ç†å™¨ï¼ˆä¿ç•™æŒ‡çº¹è¡¨ï¼‰
    experiment.run_dedup_experiment(test_data)
    
    print("\n" + "="*60)
    print("âœ… å®éªŒå®Œæˆ!")
    print("="*60)


if __name__ == "__main__":
    main()
